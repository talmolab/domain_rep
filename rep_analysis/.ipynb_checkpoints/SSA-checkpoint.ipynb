{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0225dac1-a79d-47e9-89aa-c99ef477e6af",
   "metadata": {},
   "source": [
    "# Compare Network Activations using Statistical Shape Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f08914-a856-49eb-87b9-1cde1202c7d3",
   "metadata": {},
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b087a0-a59f-47de-a72c-02f572a95fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import netrep\n",
    "import os, sys\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277d01b9-63cc-40a0-84f5-24508ddd462b",
   "metadata": {},
   "source": [
    "## Define Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4fc3e4b-9687-46f9-91f5-b9d027e5e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_model(model=None,layer_name=None):\n",
    "    layer = None\n",
    "    for l in model.layers:\n",
    "        if l.name == layer_name:\n",
    "            layer = l\n",
    "    return tf.keras.Model(model.input, layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a996b740-ecce-48b6-b8c1-12b38bf83824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_tensor(activation_model=None,stimuli_path=None):\n",
    "    with open(stimuli_path, \"rb\") as f:\n",
    "        img = tf.image.decode_jpeg(f.read())\n",
    "    if img.shape[-1]==1:\n",
    "        img = tf.image.grayscale_to_rgb(img)\n",
    "    img = tf.image.resize(img,(256,256))\n",
    "    #print(img.shape)\n",
    "    activation = activation_model(tf.expand_dims(img, axis=0))\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea67d9-320f-4347-9cdb-cd7ef7492bd3",
   "metadata": {},
   "source": [
    "## Test Statistical Shape Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4e27104-4d47-42de-a0bd-e37a1e2bdae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 18:50:14.137965: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-04 18:50:14.611831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20371 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:17:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "trained_resnet152 = tf.keras.applications.resnet.ResNet152(include_top=False, weights=\"imagenet\")\n",
    "trained_activation_model = get_activation_model(model=trained_resnet152,layer_name=\"conv4_block4_out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0407bb-5952-4c53-bd65-f475603f69f6",
   "metadata": {},
   "source": [
    "### Trained Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff08f69f-60c2-4617-895e-8e9af8381c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 18:50:18.021457: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n",
      "2022-01-04 18:50:19.661401: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 16, 16, 1024])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_activations = []\n",
    "for file in os.listdir(\"imagenet-sample-images\"):\n",
    "    if file.endswith(\".JPEG\"):\n",
    "        img = os.path.join(\"imagenet-sample-images\", file)\n",
    "        activation = tf.squeeze(get_activation_tensor(activation_model=trained_activation_model,stimuli_path=img))\n",
    "        trained_activations.append(activation)\n",
    "trained_activation = tf.stack(trained_activations)\n",
    "trained_activation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d8302-d766-4cf1-9244-e0afe913a197",
   "metadata": {},
   "source": [
    "### Untrained Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce72755-342e-4a66-80ba-759bd0dfa921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 16, 16, 1024])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untrained_resnet152 = tf.keras.applications.resnet.ResNet152(include_top=False, weights=None)\n",
    "untrained_activation_model = get_activation_model(model=untrained_resnet152,layer_name=\"conv4_block4_out\")\n",
    "untrained_activations = []\n",
    "for file in os.listdir(\"imagenet-sample-images\"):\n",
    "    if file.endswith(\".JPEG\"):\n",
    "        img = os.path.join(\"imagenet-sample-images\", file)\n",
    "        try:\n",
    "            activation = tf.squeeze(get_activation_tensor(activation_model=untrained_activation_model,stimuli_path=img))\n",
    "            untrained_activations.append(activation)\n",
    "        except ValueError:\n",
    "            print(f'shape doesnt match for {img}')\n",
    "untrained_activation = tf.stack(untrained_activations)\n",
    "untrained_activation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce9cdfa-d9d5-4b78-8a27-c413165fc755",
   "metadata": {},
   "source": [
    "### Linear Metric Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd396070-861e-46dd-bf0b-90b45979eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netrep.metrics import LinearMetric\n",
    "from netrep import conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5885edd4-b867-4e04-83b9-312a73e16d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_metric = LinearMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1230aeb-d619-4547-ae10-3db9930ffd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/256 [00:28<39:11,  9.29s/it]"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    linear_result = conv_layers.convolve_metric(linear_metric, trained_activation, untrained_activation)\n",
    "except:\n",
    "    print(\"linear metric doesn't work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190af202-15a8-4320-b061-818aab25630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(linear_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f956670e-133c-4234-b32a-f6d7c4011971",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Minimum Value for Linear Metric: {np.min(linear_result)}')\n",
    "print(f'Average Value for Linear Metric: {np.mean(linear_result)}')\n",
    "print(f'Maximum Value for Linear Metric: {np.max(linear_result)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be4be3-f813-4912-ad6f-34358e5556b7",
   "metadata": {},
   "source": [
    "### Permutation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463d95e5-24c9-4ad5-9540-90ddc02035ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netrep.metrics import PermutationMetric\n",
    "perm_metric = PermutationMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c191cc9-782c-4450-b841-2baf2678e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_result = conv_layers.convolve_metric(perm_metric,trained_activation, untrained_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a1426-aa07-4449-a31b-70ef9e60a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(perm_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5940116-d381-4775-82be-ac4d3366d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Minimum Value for Permuation Metric: {np.min(perm_result)}')\n",
    "print(f'Average Value for Permutation Metric: {np.mean(perm_result)}')\n",
    "print(f'Maximum Value for Permuation Metric: {np.max(perm_result)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4e2ea2-aaa1-46b1-b996-2537ab90441e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
